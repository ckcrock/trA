# PAPER TRADING & BACKTESTING INFRASTRUCTURE
## 6-Month Development Phase Before Live Trading

**Phase:** Paper Trading & Strategy Validation (Months 1-6)  
**Go-Live Target:** Month 7  
**Focus:** Rigorous backtesting, strategy validation, and paper trading performance verification

---

## EXECUTIVE SUMMARY

Your 6-month paper trading phase is **critical for success**. Statistics show that 90% of retail traders lose money in their first year, but those who spend 6+ months in paper trading with rigorous backtesting have significantly higher success rates.

**This document provides:**
1. ‚úÖ Industrial-grade backtesting infrastructure
2. ‚úÖ Paper trading simulation engine
3. ‚úÖ Strategy validation framework
4. ‚úÖ Performance attribution system
5. ‚úÖ Walk-forward analysis tools
6. ‚úÖ Overfitting detection methods
7. ‚úÖ 6-month development roadmap
8. ‚úÖ Go-live readiness checklist

---

## PART 1: BACKTESTING INFRASTRUCTURE (PRIORITY #1)

### 1.1 Nautilus Trader Backtesting Engine

**Why Nautilus?** It provides **backtesting-live parity** - the same code runs in both modes, eliminating the "works in backtest but fails live" problem.

**Complete Setup:**

```python
# src/backtesting/backtest_engine.py
from nautilus_trader.backtest.engine import BacktestEngine
from nautilus_trader.backtest.models import FillModel
from nautilus_trader.model.enums import AccountType, OmsType
from nautilus_trader.config import BacktestEngineConfig, BacktestRunConfig
from nautilus_trader.persistence.catalog import ParquetDataCatalog
import pandas as pd
from pathlib import Path

class EnhancedBacktestEngine:
    """
    Production-grade backtesting engine with Indian market specifics.
    """
    
    def __init__(
        self,
        data_path: str = "data/catalog",
        output_path: str = "backtests/results"
    ):
        self.data_path = Path(data_path)
        self.output_path = Path(output_path)
        self.catalog = ParquetDataCatalog(str(self.data_path))
        
        # Indian market parameters
        self.trading_hours = {
            "market_open": "09:15:00",
            "market_close": "15:30:00",
            "pre_open_start": "09:00:00",
            "pre_open_end": "09:15:00"
        }
        
        # Backtesting configuration
        self.config = BacktestEngineConfig(
            trader_id="BACKTESTER-001",
            logging=LoggingConfig(
                log_level="INFO",
                log_level_file="DEBUG",
                log_directory=str(self.output_path / "logs")
            ),
            # CRITICAL: Use BAR data engine for realistic backtests
            # Tick-by-tick is unrealistic for retail traders
            run_analysis=True,
            snapshot_orders=True,
            snapshot_positions=True
        )
    
    def create_realistic_fill_model(self) -> FillModel:
        """
        Create realistic fill model for Indian markets.
        
        CRITICAL: Default Nautilus fill model assumes instant fills
        at mid-price. This is UNREALISTIC for retail traders.
        
        Indian Market Realities:
        - Market orders: 1-3 tick slippage
        - Limit orders: Partial fills common
        - Low liquidity stocks: High slippage (5-10 ticks)
        - High volatility: Slippage increases
        """
        from nautilus_trader.backtest.models import FillModel
        from nautilus_trader.model.data import OrderBookDelta, QuoteTick
        
        class IndianMarketFillModel(FillModel):
            """
            Realistic fill model for NSE/BSE.
            """
            
            def __init__(self):
                super().__init__()
                self.slippage_ticks = {
                    "MARKET": 2,  # 2 tick slippage for market orders
                    "LIMIT": 0,   # Limit orders fill at limit price
                    "STOP": 3,    # 3 tick slippage for stop orders
                }
                self.partial_fill_probability = 0.15  # 15% chance of partial fill
            
            def is_limit_matched(
                self,
                order_side,
                order_price,
                market_price,
                is_ask_side
            ) -> bool:
                """
                Determine if limit order should fill.
                
                Conservative approach: Only fill if market clearly
                crosses the limit price.
                """
                if order_side == "BUY":
                    # Buy limit fills when ask <= limit price
                    return market_price <= order_price
                else:
                    # Sell limit fills when bid >= limit price
                    return market_price >= order_price
            
            def get_market_order_fill_price(
                self,
                order_side,
                market_bid,
                market_ask
            ):
                """
                Calculate realistic market order fill price.
                
                Indian Market Reality:
                - You pay the ask when buying
                - You receive the bid when selling
                - Plus slippage (1-3 ticks typical)
                """
                tick_size = 0.05  # ‚Çπ0.05 for most stocks
                slippage = self.slippage_ticks["MARKET"] * tick_size
                
                if order_side == "BUY":
                    return market_ask + slippage
                else:
                    return market_bid - slippage
            
            def should_partial_fill(self) -> bool:
                """
                Simulate partial fills (common in illiquid stocks).
                """
                import random
                return random.random() < self.partial_fill_probability
        
        return IndianMarketFillModel()
    
    def add_transaction_costs(self) -> dict:
        """
        Add realistic transaction costs for Indian markets.
        
        Total Cost Breakdown (per trade):
        - Brokerage: ‚Çπ20 or 0.03% (whichever lower for discount brokers)
        - STT (Securities Transaction Tax):
          * Delivery: 0.1% on buy and sell
          * Intraday: 0.025% on sell side only
        - Transaction charges: 0.00325% (NSE)
        - GST: 18% on brokerage + transaction charges
        - SEBI charges: 0.0001%
        - Stamp duty: 0.003% on buy side (varies by state)
        
        TOTAL: ~0.30% - 0.60% per round trip
        """
        return {
            "brokerage_per_trade": 20.0,  # Flat ‚Çπ20
            "brokerage_percentage": 0.0003,  # 0.03%
            "stt_delivery": 0.001,  # 0.1% on both sides
            "stt_intraday": 0.00025,  # 0.025% on sell
            "transaction_charges": 0.0000325,  # NSE charges
            "gst_rate": 0.18,  # 18% on brokerage + transaction
            "sebi_charges": 0.000001,  # 0.0001%
            "stamp_duty": 0.00003,  # 0.003% on buy
        }
    
    def calculate_realistic_costs(
        self,
        trade_value: float,
        product_type: str  # "DELIVERY" or "INTRADAY"
    ) -> float:
        """
        Calculate total transaction cost.
        
        Example:
        - Trade value: ‚Çπ10,000
        - Brokerage: min(‚Çπ20, ‚Çπ3) = ‚Çπ3
        - STT (intraday): ‚Çπ2.50
        - Transaction charges: ‚Çπ0.33
        - GST: ‚Çπ0.60
        - SEBI: ‚Çπ0.01
        - Stamp duty: ‚Çπ0.30
        - TOTAL: ‚Çπ6.74 (0.067%)
        
        For both buy + sell: ‚Çπ13.48 (0.135% of ‚Çπ10k)
        """
        costs = self.add_transaction_costs()
        
        # Brokerage (whichever is lower)
        brokerage = min(
            costs["brokerage_per_trade"],
            trade_value * costs["brokerage_percentage"]
        )
        
        # STT
        if product_type == "DELIVERY":
            stt = trade_value * costs["stt_delivery"] * 2  # Buy + Sell
        else:  # INTRADAY
            stt = trade_value * costs["stt_intraday"]  # Sell only
        
        # Transaction charges
        transaction_charges = trade_value * costs["transaction_charges"]
        
        # GST on brokerage + transaction charges
        gst = (brokerage + transaction_charges) * costs["gst_rate"]
        
        # SEBI charges
        sebi = trade_value * costs["sebi_charges"]
        
        # Stamp duty (buy side only)
        stamp_duty = trade_value * costs["stamp_duty"]
        
        # Total one-way cost
        one_way_cost = (
            brokerage + stt + transaction_charges + 
            gst + sebi + stamp_duty
        )
        
        # Round trip (buy + sell)
        return one_way_cost * 2
    
    async def run_backtest(
        self,
        strategy_class,
        strategy_config: dict,
        instruments: list[str],
        start_date: str,
        end_date: str,
        initial_capital: float = 100000.0,
        bar_type: str = "5-MINUTE"
    ) -> dict:
        """
        Run comprehensive backtest with all enhancements.
        
        Args:
            strategy_class: Strategy class to test
            strategy_config: Strategy parameters
            instruments: List of symbols to trade
            start_date: "YYYY-MM-DD"
            end_date: "YYYY-MM-DD"
            initial_capital: Starting capital (‚Çπ)
            bar_type: "1-MINUTE", "5-MINUTE", "15-MINUTE", "1-HOUR", "1-DAY"
        
        Returns:
            Comprehensive backtest results
        """
        
        # Initialize backtest engine
        engine = BacktestEngine(config=self.config)
        
        # Add venue (NSE/BSE)
        engine.add_venue(
            venue="NSE",
            oms_type=OmsType.NETTING,
            account_type=AccountType.MARGIN,
            base_currency="INR",
            starting_balances=["100000 INR"]  # Initial capital
        )
        
        # Load instruments
        for symbol in instruments:
            instrument = self.catalog.instruments(
                instrument_ids=[f"{symbol}.NSE"]
            )[0]
            engine.add_instrument(instrument)
        
        # Load historical data
        for symbol in instruments:
            bars = self.catalog.bars(
                instrument_ids=[f"{symbol}.NSE"],
                bar_type=bar_type,
                start=start_date,
                end=end_date
            )
            engine.add_data(bars)
        
        # Add strategy
        strategy = strategy_class(**strategy_config)
        engine.add_strategy(strategy)
        
        # Configure realistic execution
        engine.add_fill_model(self.create_realistic_fill_model())
        
        # Run backtest
        engine.run()
        
        # Generate comprehensive report
        results = self.generate_backtest_report(engine)
        
        # Save results
        self.save_backtest_results(results, strategy_class.__name__)
        
        return results
    
    def generate_backtest_report(self, engine: BacktestEngine) -> dict:
        """
        Generate comprehensive backtest statistics.
        
        Returns all critical metrics for strategy evaluation.
        """
        account = engine.trader.generate_account_report("NSE")
        
        # Extract key metrics
        trades = account.trades
        total_trades = len(trades)
        
        if total_trades == 0:
            return {"error": "No trades executed"}
        
        # Calculate P&L
        total_pnl = sum(trade.realized_pnl for trade in trades)
        winning_trades = [t for t in trades if t.realized_pnl > 0]
        losing_trades = [t for t in trades if t.realized_pnl < 0]
        
        win_rate = len(winning_trades) / total_trades if total_trades > 0 else 0
        
        avg_win = (
            sum(t.realized_pnl for t in winning_trades) / len(winning_trades)
            if winning_trades else 0
        )
        avg_loss = (
            sum(t.realized_pnl for t in losing_trades) / len(losing_trades)
            if losing_trades else 0
        )
        
        # Risk metrics
        profit_factor = (
            abs(sum(t.realized_pnl for t in winning_trades) / 
                sum(t.realized_pnl for t in losing_trades))
            if losing_trades else float('inf')
        )
        
        # Calculate Sharpe Ratio
        returns = pd.Series([t.realized_pnl for t in trades])
        sharpe_ratio = (
            returns.mean() / returns.std() * np.sqrt(252)
            if returns.std() > 0 else 0
        )
        
        # Calculate Max Drawdown
        cumulative_returns = returns.cumsum()
        running_max = cumulative_returns.expanding().max()
        drawdown = cumulative_returns - running_max
        max_drawdown = drawdown.min()
        max_drawdown_pct = (max_drawdown / 100000) * 100  # As % of capital
        
        return {
            "total_trades": total_trades,
            "winning_trades": len(winning_trades),
            "losing_trades": len(losing_trades),
            "win_rate": win_rate,
            "total_pnl": total_pnl,
            "total_pnl_percent": (total_pnl / 100000) * 100,
            "avg_win": avg_win,
            "avg_loss": avg_loss,
            "profit_factor": profit_factor,
            "sharpe_ratio": sharpe_ratio,
            "max_drawdown": max_drawdown,
            "max_drawdown_percent": max_drawdown_pct,
            "avg_trade_duration": self._calculate_avg_duration(trades),
            "largest_win": max((t.realized_pnl for t in trades), default=0),
            "largest_loss": min((t.realized_pnl for t in trades), default=0),
        }
    
    def save_backtest_results(self, results: dict, strategy_name: str):
        """
        Save backtest results to file and database.
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.output_path / f"{strategy_name}_{timestamp}.json"
        
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        logger.info(f"Backtest results saved to: {output_file}")
```

### 1.2 Walk-Forward Analysis (CRITICAL)

**Purpose:** Detect overfitting by testing strategy on unseen data.

**Methodology:**
- Split data into training and testing windows
- Optimize on training window
- Validate on testing window
- Roll forward and repeat

```python
# src/backtesting/walk_forward.py
class WalkForwardAnalyzer:
    """
    Walk-forward analysis to prevent overfitting.
    
    Example Timeline:
    - Total data: Jan 2023 - Dec 2025 (3 years)
    - Training window: 6 months
    - Testing window: 1 month
    - Step size: 1 month
    
    Process:
    1. Train on Jan-Jun 2023, test on Jul 2023
    2. Train on Feb-Jul 2023, test on Aug 2023
    3. Continue rolling forward...
    
    Result: 30+ out-of-sample tests
    """
    
    def __init__(
        self,
        training_window_months: int = 6,
        testing_window_months: int = 1,
        step_size_months: int = 1
    ):
        self.training_window = training_window_months
        self.testing_window = testing_window_months
        self.step_size = step_size_months
    
    async def run_walk_forward(
        self,
        strategy_class,
        parameter_ranges: dict,
        instruments: list[str],
        start_date: str,
        end_date: str
    ) -> dict:
        """
        Run walk-forward analysis.
        
        Args:
            strategy_class: Strategy to test
            parameter_ranges: Parameters to optimize
              Example: {
                  "fast_period": [5, 9, 12],
                  "slow_period": [20, 26, 30],
                  "risk_per_trade": [0.01, 0.02]
              }
            instruments: Symbols to trade
            start_date: Overall start
            end_date: Overall end
        
        Returns:
            Walk-forward results with consistency metrics
        """
        results = []
        
        # Generate training/testing windows
        windows = self._generate_windows(start_date, end_date)
        
        for i, (train_start, train_end, test_start, test_end) in enumerate(windows):
            logger.info(f"Window {i+1}/{len(windows)}")
            logger.info(f"  Training: {train_start} to {train_end}")
            logger.info(f"  Testing: {test_start} to {test_end}")
            
            # 1. Optimize parameters on training data
            best_params = await self._optimize_parameters(
                strategy_class,
                parameter_ranges,
                instruments,
                train_start,
                train_end
            )
            
            # 2. Test on unseen data
            test_results = await self.backtest_engine.run_backtest(
                strategy_class=strategy_class,
                strategy_config=best_params,
                instruments=instruments,
                start_date=test_start,
                end_date=test_end
            )
            
            results.append({
                "window": i + 1,
                "train_period": f"{train_start} to {train_end}",
                "test_period": f"{test_start} to {test_end}",
                "optimized_params": best_params,
                "test_performance": test_results
            })
        
        # Analyze consistency across windows
        consistency_report = self._analyze_consistency(results)
        
        return {
            "individual_windows": results,
            "consistency_metrics": consistency_report,
            "recommendation": self._generate_recommendation(consistency_report)
        }
    
    def _analyze_consistency(self, results: list) -> dict:
        """
        Analyze performance consistency across windows.
        
        Key Metrics:
        - Win rate std dev (lower = more consistent)
        - Sharpe ratio std dev
        - Max drawdown variation
        - Profitability consistency (% of profitable windows)
        
        RED FLAGS:
        - High variance in win rate (>10%)
        - Many losing windows (>30%)
        - Increasing drawdowns over time
        """
        win_rates = [r["test_performance"]["win_rate"] for r in results]
        sharpe_ratios = [r["test_performance"]["sharpe_ratio"] for r in results]
        pnls = [r["test_performance"]["total_pnl"] for r in results]
        
        profitable_windows = sum(1 for pnl in pnls if pnl > 0)
        consistency_score = profitable_windows / len(results)
        
        return {
            "win_rate_mean": np.mean(win_rates),
            "win_rate_std": np.std(win_rates),
            "sharpe_mean": np.mean(sharpe_ratios),
            "sharpe_std": np.std(sharpe_ratios),
            "profitable_windows_pct": consistency_score,
            "total_windows": len(results),
            "is_consistent": consistency_score >= 0.70,  # 70% threshold
        }
    
    def _generate_recommendation(self, consistency: dict) -> str:
        """
        Generate go/no-go recommendation.
        
        Criteria for GO LIVE:
        - Profitable in 70%+ of windows
        - Win rate std dev < 10%
        - Sharpe ratio > 1.0 average
        - No catastrophic drawdowns
        """
        if consistency["profitable_windows_pct"] < 0.70:
            return "‚ùå NOT READY: Profitable in <70% of windows. High overfitting risk."
        
        if consistency["win_rate_std"] > 0.10:
            return "‚ùå NOT READY: Win rate too inconsistent (std > 10%)."
        
        if consistency["sharpe_mean"] < 1.0:
            return "‚ö†Ô∏è CAUTION: Low average Sharpe ratio (<1.0). Risk-adjusted returns poor."
        
        return "‚úÖ READY: Strategy shows consistent performance across windows."
```

### 1.3 Monte Carlo Simulation

**Purpose:** Understand range of possible outcomes and worst-case scenarios.

```python
# src/backtesting/monte_carlo.py
class MonteCarloSimulator:
    """
    Monte Carlo simulation for strategy robustness testing.
    
    Method: Randomly re-shuffle historical trades to generate
    thousands of alternate equity curves.
    
    Use Cases:
    - Estimate probability of ruin
    - Calculate confidence intervals for returns
    - Identify worst-case drawdown scenarios
    """
    
    def __init__(self, num_simulations: int = 10000):
        self.num_simulations = num_simulations
    
    def simulate(self, historical_trades: list) -> dict:
        """
        Run Monte Carlo simulation.
        
        Args:
            historical_trades: List of trade P&Ls from backtest
        
        Returns:
            Statistical distribution of outcomes
        """
        trade_returns = [trade.realized_pnl for trade in historical_trades]
        
        simulated_equity_curves = []
        final_capitals = []
        max_drawdowns = []
        
        for i in range(self.num_simulations):
            # Randomly resample trades (with replacement)
            shuffled_trades = np.random.choice(
                trade_returns,
                size=len(trade_returns),
                replace=True
            )
            
            # Generate equity curve
            equity_curve = np.cumsum(shuffled_trades)
            simulated_equity_curves.append(equity_curve)
            
            # Track final capital
            final_capitals.append(equity_curve[-1])
            
            # Calculate max drawdown
            running_max = np.maximum.accumulate(equity_curve)
            drawdown = equity_curve - running_max
            max_drawdowns.append(drawdown.min())
        
        # Statistical analysis
        final_capitals = np.array(final_capitals)
        max_drawdowns = np.array(max_drawdowns)
        
        return {
            "mean_final_capital": np.mean(final_capitals),
            "median_final_capital": np.median(final_capitals),
            "std_final_capital": np.std(final_capitals),
            "confidence_intervals": {
                "95%": (
                    np.percentile(final_capitals, 2.5),
                    np.percentile(final_capitals, 97.5)
                ),
                "99%": (
                    np.percentile(final_capitals, 0.5),
                    np.percentile(final_capitals, 99.5)
                )
            },
            "probability_of_profit": (
                np.sum(final_capitals > 0) / self.num_simulations
            ),
            "worst_case_drawdown": np.percentile(max_drawdowns, 1),  # 1st percentile
            "median_drawdown": np.median(max_drawdowns),
            "best_case_scenario": np.percentile(final_capitals, 99),
            "worst_case_scenario": np.percentile(final_capitals, 1),
        }
    
    def visualize_distribution(self, results: dict):
        """
        Plot distribution of outcomes.
        """
        import matplotlib.pyplot as plt
        
        plt.figure(figsize=(12, 6))
        
        # Histogram of final capitals
        plt.subplot(1, 2, 1)
        plt.hist(results["simulated_equity_curves"], bins=50, alpha=0.7)
        plt.axvline(results["mean_final_capital"], color='r', linestyle='--', label='Mean')
        plt.axvline(results["median_final_capital"], color='g', linestyle='--', label='Median')
        plt.title("Distribution of Final Capital")
        plt.xlabel("Final Capital (‚Çπ)")
        plt.ylabel("Frequency")
        plt.legend()
        
        # Drawdown distribution
        plt.subplot(1, 2, 2)
        plt.hist(results["max_drawdowns"], bins=50, alpha=0.7, color='orange')
        plt.title("Distribution of Max Drawdown")
        plt.xlabel("Max Drawdown (‚Çπ)")
        plt.ylabel("Frequency")
        
        plt.tight_layout()
        plt.savefig("monte_carlo_results.png")
```

---

## PART 2: HISTORICAL DATA MANAGEMENT

### 2.1 Data Download & Storage

```python
# src/data/historical_data_manager.py
class HistoricalDataManager:
    """
    Manage historical data download and storage.
    
    Data Sources:
    - Angel One SmartAPI (primary)
    - NSE/BSE historical data (free, but delayed)
    - Third-party vendors (paid, better quality)
    """
    
    def __init__(self, catalog_path: str = "data/catalog"):
        self.catalog = ParquetDataCatalog(catalog_path)
        self.angel_client = AngelDataClient()
    
    async def download_historical_data(
        self,
        symbols: list[str],
        start_date: str,
        end_date: str,
        interval: str = "5minute",  # "1minute", "5minute", "15minute", "day"
        exchange: str = "NSE"
    ):
        """
        Download and store historical data.
        
        IMPORTANT: Angel One rate limits
        - 3 requests/second for historical data
        - Maximum 1 year per request
        - Best practice: Download overnight, not during trading hours
        """
        for symbol in symbols:
            logger.info(f"Downloading {symbol} from {start_date} to {end_date}")
            
            # Respect rate limits
            await self.angel_client.rate_limiter.acquire_async()
            
            # Download data
            bars = await self.angel_client.get_historical_data(
                symbol=symbol,
                exchange=exchange,
                from_date=start_date,
                to_date=end_date,
                interval=interval
            )
            
            # Store in Parquet format
            self.catalog.write_data(bars, instrument_id=f"{symbol}.{exchange}")
            
            logger.info(f"Stored {len(bars)} bars for {symbol}")
    
    def validate_data_quality(self, symbol: str) -> dict:
        """
        Data quality checks (CRITICAL for backtest accuracy).
        
        Checks:
        - Missing bars (gaps in data)
        - Duplicate timestamps
        - Zero volume bars
        - Unrealistic price movements (>20% in 1 bar)
        - Bid-ask spread validation
        - OHLC consistency (H >= C,O,L; L <= C,O,H)
        """
        bars = self.catalog.bars(instrument_ids=[symbol])
        
        issues = []
        
        # Check for gaps
        expected_bars = self._calculate_expected_bars(
            bars[0].timestamp,
            bars[-1].timestamp,
            interval="5MIN"
        )
        
        if len(bars) < expected_bars * 0.95:  # Allow 5% tolerance
            issues.append(f"Missing data: {len(bars)}/{expected_bars} bars")
        
        # Check for duplicates
        timestamps = [bar.timestamp for bar in bars]
        if len(timestamps) != len(set(timestamps)):
            issues.append("Duplicate timestamps detected")
        
        # Check OHLC validity
        for bar in bars:
            if not (bar.low <= bar.close <= bar.high and 
                    bar.low <= bar.open <= bar.high):
                issues.append(f"Invalid OHLC at {bar.timestamp}")
        
        return {
            "symbol": symbol,
            "total_bars": len(bars),
            "expected_bars": expected_bars,
            "completeness": len(bars) / expected_bars,
            "issues": issues,
            "quality_score": 100 - len(issues) * 10  # Simple scoring
        }
```

### 2.2 Data Storage Recommendations

**Required Historical Data (Minimum):**
- **Stocks:** Top 50 Nifty stocks + 50 mid-caps = 100 symbols
- **Timeframes:** 1-min, 5-min, 15-min, Daily
- **Duration:** 3 years (Jan 2022 - Feb 2025)
- **Total Size:** ~50-100 GB (compressed Parquet)

**Storage Structure:**
```
data/catalog/
‚îú‚îÄ‚îÄ NSE/
‚îÇ   ‚îú‚îÄ‚îÄ SBIN/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1MIN/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2022-01.parquet
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2022-02.parquet
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5MIN/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DAILY/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ BSE/
```

---

## PART 3: PAPER TRADING ENGINE

### 3.1 Production-Grade Paper Trading

```python
# src/paper_trading/paper_engine.py
class PaperTradingEngine:
    """
    Paper trading with realistic execution simulation.
    
    CRITICAL: Paper trading must be AS REALISTIC AS POSSIBLE.
    Common mistakes:
    - Instant fills at mid-price (unrealistic)
    - No slippage
    - No transaction costs
    - No partial fills
    - No order rejections
    
    Our implementation simulates ALL real-world conditions.
    """
    
    def __init__(self, initial_capital: float = 100000.0):
        self.capital = initial_capital
        self.available_margin = initial_capital
        self.positions = {}
        self.orders = {}
        self.trade_history = []
        
        # Realistic execution parameters
        self.slippage_model = SlippageModel()
        self.cost_model = TransactionCostModel()
        self.fill_probability_model = FillProbabilityModel()
        
        # Track metrics
        self.metrics = {
            "total_trades": 0,
            "winning_trades": 0,
            "losing_trades": 0,
            "total_pnl": 0.0,
            "max_drawdown": 0.0,
        }
    
    async def place_order(
        self,
        symbol: str,
        side: str,  # "BUY" or "SELL"
        quantity: int,
        order_type: str,  # "MARKET" or "LIMIT"
        price: float = None,  # For limit orders
        product_type: str = "MIS"
    ) -> dict:
        """
        Simulate order placement with realistic execution.
        
        Returns order confirmation or rejection.
        """
        # 1. Validate order (RMS checks)
        validation = self._validate_order(symbol, side, quantity, price, product_type)
        if not validation["valid"]:
            return {
                "status": "REJECTED",
                "reason": validation["reason"],
                "error_code": validation["error_code"]
            }
        
        # 2. Check circuit breakers
        if self._is_circuit_locked(symbol):
            return {
                "status": "REJECTED",
                "reason": f"{symbol} is circuit-locked",
                "error_code": "CIRCUIT_LIMIT"
            }
        
        # 3. Calculate required margin
        required_margin = self._calculate_margin(
            symbol, quantity, price or self._get_ltp(symbol), product_type
        )
        
        if required_margin > self.available_margin:
            return {
                "status": "REJECTED",
                "reason": "Insufficient margin",
                "error_code": "AB2005",
                "required": required_margin,
                "available": self.available_margin
            }
        
        # 4. Simulate order execution
        if order_type == "MARKET":
            # Market orders execute immediately (with slippage)
            fill_price = await self._execute_market_order(symbol, side, quantity)
            
            # Apply transaction costs
            costs = self.cost_model.calculate(
                trade_value=quantity * fill_price,
                product_type=product_type
            )
            
            # Update position
            self._update_position(symbol, side, quantity, fill_price, costs)
            
            return {
                "status": "COMPLETE",
                "order_id": self._generate_order_id(),
                "fill_price": fill_price,
                "quantity": quantity,
                "transaction_cost": costs,
                "timestamp": datetime.now()
            }
        
        elif order_type == "LIMIT":
            # Limit orders go into pending queue
            order_id = self._generate_order_id()
            self.orders[order_id] = {
                "symbol": symbol,
                "side": side,
                "quantity": quantity,
                "limit_price": price,
                "status": "PENDING",
                "product_type": product_type
            }
            
            return {
                "status": "OPEN",
                "order_id": order_id,
                "message": "Limit order placed, awaiting execution"
            }
    
    async def _execute_market_order(
        self,
        symbol: str,
        side: str,
        quantity: int
    ) -> float:
        """
        Simulate realistic market order execution.
        
        Execution logic:
        - Get current bid/ask from live feed
        - Apply slippage (1-3 ticks typical)
        - Simulate partial fills for large orders
        """
        current_quote = await self._get_current_quote(symbol)
        
        if side == "BUY":
            # Buy at ask + slippage
            base_price = current_quote["ask"]
            slippage = self.slippage_model.calculate(
                symbol=symbol,
                order_size=quantity,
                market_condition="NORMAL"
            )
            fill_price = base_price + slippage
        else:
            # Sell at bid - slippage
            base_price = current_quote["bid"]
            slippage = self.slippage_model.calculate(
                symbol=symbol,
                order_size=quantity,
                market_condition="NORMAL"
            )
            fill_price = base_price - slippage
        
        # Simulate partial fill for large orders
        if quantity > 1000:  # Example threshold
            if random.random() < 0.20:  # 20% chance of partial fill
                logger.warning(f"Partial fill: {quantity} -> {quantity//2}")
                # In reality, would need to handle partial fill logic
        
        return fill_price
    
    async def monitor_limit_orders(self):
        """
        Background task to check limit order fills.
        
        Runs every second during market hours.
        """
        while True:
            for order_id, order in list(self.orders.items()):
                if order["status"] != "PENDING":
                    continue
                
                current_price = await self._get_ltp(order["symbol"])
                
                # Check if limit price hit
                should_fill = (
                    (order["side"] == "BUY" and current_price <= order["limit_price"]) or
                    (order["side"] == "SELL" and current_price >= order["limit_price"])
                )
                
                if should_fill:
                    # Simulate fill probability (not 100% even if price hit)
                    if self.fill_probability_model.should_fill():
                        await self._fill_limit_order(order_id, order)
            
            await asyncio.sleep(1)  # Check every second
    
    def get_performance_report(self) -> dict:
        """
        Generate real-time performance report.
        
        Metrics to track during paper trading:
        - Total P&L (realized + unrealized)
        - Win rate
        - Average win/loss
        - Sharpe ratio (rolling 30 days)
        - Max drawdown
        - Number of trades per day
        - Capital utilization
        - Comparison to backtest expectations
        """
        total_pnl = self.metrics["total_pnl"] + self._calculate_unrealized_pnl()
        
        return {
            "total_trades": self.metrics["total_trades"],
            "win_rate": (
                self.metrics["winning_trades"] / self.metrics["total_trades"]
                if self.metrics["total_trades"] > 0 else 0
            ),
            "total_pnl": total_pnl,
            "total_pnl_percent": (total_pnl / self.capital) * 100,
            "max_drawdown": self.metrics["max_drawdown"],
            "sharpe_ratio": self._calculate_sharpe(),
            "open_positions": len(self.positions),
            "available_margin": self.available_margin,
            "margin_utilization": (
                (self.capital - self.available_margin) / self.capital * 100
            )
        }
```

---

## PART 4: STRATEGY VALIDATION FRAMEWORK

### 4.1 Overfitting Detection

```python
# src/validation/overfitting_detector.py
class OverfittingDetector:
    """
    Detect if strategy is overfitted to historical data.
    
    RED FLAGS for Overfitting:
    1. Too many parameters (>5-7)
    2. Perfect backtest (win rate >80%, Sharpe >3)
    3. Performance degrades on out-of-sample data
    4. High parameter sensitivity
    5. Works only on specific date ranges
    """
    
    def check_parameter_count(self, strategy_config: dict) -> dict:
        """
        Rule of thumb: More parameters = higher overfitting risk.
        
        Acceptable:
        - 1-3 parameters: Low risk
        - 4-5 parameters: Medium risk
        - 6+ parameters: High risk (likely overfit)
        """
        param_count = len(strategy_config)
        
        if param_count <= 3:
            return {"risk": "LOW", "message": "Acceptable parameter count"}
        elif param_count <= 5:
            return {"risk": "MEDIUM", "message": "Monitor for overfitting"}
        else:
            return {"risk": "HIGH", "message": "Too many parameters - high overfit risk"}
    
    def check_parameter_sensitivity(
        self,
        strategy_class,
        base_params: dict,
        test_data: dict
    ) -> dict:
        """
        Test how sensitive strategy is to parameter changes.
        
        Good strategy: Robust to small parameter changes
        Overfit strategy: Performance collapses with slight param tweaks
        
        Example:
        - Base: fast_ema=9, slow_ema=21 ‚Üí Sharpe 1.5
        - Test: fast_ema=8, slow_ema=20 ‚Üí Sharpe 1.4 (GOOD)
        - Test: fast_ema=10, slow_ema=22 ‚Üí Sharpe 0.2 (BAD - overfit!)
        """
        base_performance = self._run_test(strategy_class, base_params, test_data)
        
        sensitivities = []
        
        for param_name, param_value in base_params.items():
            if isinstance(param_value, (int, float)):
                # Test ¬±10% variation
                variations = [
                    param_value * 0.9,
                    param_value * 1.1
                ]
                
                for new_value in variations:
                    modified_params = base_params.copy()
                    modified_params[param_name] = new_value
                    
                    new_performance = self._run_test(
                        strategy_class, modified_params, test_data
                    )
                    
                    performance_drop = (
                        base_performance["sharpe_ratio"] - 
                        new_performance["sharpe_ratio"]
                    )
                    
                    sensitivities.append({
                        "parameter": param_name,
                        "original": param_value,
                        "tested": new_value,
                        "performance_drop": performance_drop
                    })
        
        avg_sensitivity = np.mean([s["performance_drop"] for s in sensitivities])
        
        if avg_sensitivity > 0.5:
            return {
                "risk": "HIGH",
                "message": "Strategy highly sensitive to parameters - likely overfit",
                "avg_sensitivity": avg_sensitivity
            }
        else:
            return {
                "risk": "LOW",
                "message": "Strategy robust to parameter changes",
                "avg_sensitivity": avg_sensitivity
            }
```

---

## PART 5: 6-MONTH DEVELOPMENT ROADMAP

### Month 1-2: Infrastructure Setup
**Goal:** Build foundation for backtesting and data management

**Week 1-2:**
- [ ] Set up Nautilus Trader environment
- [ ] Create Parquet data catalog
- [ ] Download 3 years of historical data (Top 100 NSE stocks)
- [ ] Implement data quality validation
- [ ] Test data completeness (aim for >95%)

**Week 3-4:**
- [ ] Build enhanced backtest engine
- [ ] Implement realistic fill model
- [ ] Add transaction cost calculator
- [ ] Create slippage model
- [ ] Run first test backtest

**Week 5-6:**
- [ ] Implement Monte Carlo simulator
- [ ] Build walk-forward analysis framework
- [ ] Create overfitting detector
- [ ] Document all systems

**Week 7-8:**
- [ ] Set up paper trading engine
- [ ] Connect to Angel One live feed
- [ ] Test WebSocket stability
- [ ] Implement order simulation

**Deliverables:**
- ‚úÖ 3 years of clean historical data
- ‚úÖ Working backtest engine
- ‚úÖ Paper trading engine (basic)
- ‚úÖ All infrastructure code tested

---

### Month 3-4: Strategy Development & Testing
**Goal:** Develop and validate 3-5 profitable strategies

**Week 9-10:**
- [ ] Implement 5 indicator-based strategies:
  1. EMA Crossover (9/21)
  2. RSI Mean Reversion (14-period)
  3. VWAP Bounce
  4. Supertrend Following
  5. Opening Range Breakout

**Week 11-12:**
- [ ] Run comprehensive backtests (all strategies, all stocks)
- [ ] Analyze results:
  - Win rate, Sharpe ratio, max drawdown
  - Trade frequency
  - Best/worst performing stocks
- [ ] Eliminate underperforming strategies

**Week 13-14:**
- [ ] Walk-forward analysis (remaining strategies)
- [ ] Parameter optimization
- [ ] Out-of-sample testing
- [ ] Monte Carlo simulation

**Week 15-16:**
- [ ] Refine strategies based on results
- [ ] Combine best strategies into portfolio
- [ ] Test portfolio performance
- [ ] Document strategy logic

**Deliverables:**
- ‚úÖ 3 validated strategies (70%+ profitable windows)
- ‚úÖ Walk-forward analysis reports
- ‚úÖ Monte Carlo confidence intervals
- ‚úÖ Complete strategy documentation

---

### Month 5: Paper Trading Validation
**Goal:** Verify backtest results match live performance

**Week 17-18:**
- [ ] Deploy strategies to paper trading
- [ ] Monitor real-time execution
- [ ] Track slippage vs backtest assumptions
- [ ] Compare paper results to backtest expectations

**Week 19-20:**
- [ ] Analyze discrepancies:
  - Are fills realistic?
  - Is slippage as expected?
  - Are transaction costs accurate?
  - Any missing edge cases?
- [ ] Adjust backtest models if needed
- [ ] Re-run backtests with updated assumptions

**Metrics to Track:**
- Paper trading P&L vs backtest P&L (should be within 20%)
- Win rate delta (<5% acceptable)
- Average slippage (<0.1% for liquid stocks)
- Order rejection rate (<1%)

**Deliverables:**
- ‚úÖ 1 month of paper trading data
- ‚úÖ Backtest-to-live reconciliation report
- ‚úÖ Updated execution models
- ‚úÖ Performance attribution analysis

---

### Month 6: Production Preparation
**Goal:** Prepare for live trading launch

**Week 21-22:**
- [ ] Implement all SEBI compliance requirements
- [ ] Register algorithms with exchange
- [ ] Get static IP from ISP
- [ ] Set up 2FA authentication
- [ ] Implement audit trail (5-year retention)

**Week 23:**
- [ ] Build circuit breaker protection
- [ ] Implement auto square-off logic
- [ ] Add product type management (MIS/CNC/NRML)
- [ ] Test all risk controls

**Week 24:**
- [ ] Final paper trading review
- [ ] Calculate exact go-live capital (based on max drawdown)
- [ ] Prepare broker account funding
- [ ] Create incident response playbook

**Go-Live Checklist:**
- [ ] All strategies profitable in paper trading (Month 5)
- [ ] Backtest-live parity confirmed (<20% deviation)
- [ ] SEBI compliance complete
- [ ] Risk controls tested
- [ ] Capital allocated (start with 10-20% of total)
- [ ] Emergency stop procedures documented
- [ ] Monitoring dashboards operational
- [ ] Alerts configured
- [ ] Team trained on all procedures

**Deliverables:**
- ‚úÖ Production-ready system
- ‚úÖ Compliance documentation
- ‚úÖ Go-live runbook
- ‚úÖ Incident response plan

---

## PART 6: SUCCESS CRITERIA

### Backtesting Benchmarks

**Minimum Requirements for Go-Live:**

| Metric | Minimum | Good | Excellent |
|--------|---------|------|-----------|
| Win Rate | >50% | >55% | >60% |
| Sharpe Ratio | >1.0 | >1.5 | >2.0 |
| Profit Factor | >1.3 | >1.5 | >2.0 |
| Max Drawdown | <15% | <10% | <5% |
| Walk-Forward Consistency | >65% | >70% | >80% |
| Monte Carlo Profit Probability | >70% | >80% | >90% |

**Red Flags (DO NOT GO LIVE):**
- ‚ùå Win rate <45%
- ‚ùå Sharpe ratio <0.5
- ‚ùå Max drawdown >20%
- ‚ùå Profitable in <60% of walk-forward windows
- ‚ùå High parameter sensitivity
- ‚ùå Paper trading results significantly worse than backtest

---

## PART 7: POST-GO-LIVE MONITORING

### First 3 Months Live Trading

**Week 1 (Critical):**
- Start with 10% of planned capital
- Trade smallest position sizes
- Monitor EVERY trade manually
- Daily performance review
- Compare to paper trading expectations

**Month 1:**
- If performance within 20% of paper trading: ‚úÖ Continue
- If performance worse than 30%: üõë STOP and investigate
- Gradually increase position sizes (10% ‚Üí 25% capital)

**Month 2-3:**
- Scale to 50% capital if Month 1 successful
- Continue daily monitoring
- Track live vs backtest deviations
- Refine execution models

**Go to 100% Capital Only If:**
- 3 months of consistent profitability
- Live performance within 20% of backtest
- No major unexpected issues
- All risk controls working properly

---

## CONCLUSION

Your 6-month paper trading phase is an **investment, not a delay**. The Indian stock market has a 90% trader failure rate, primarily due to:
1. Insufficient testing
2. Overfitted strategies
3. Unrealistic backtest assumptions
4. Poor risk management

By following this roadmap, you'll:
- ‚úÖ Validate strategies on 3 years of data
- ‚úÖ Test robustness via walk-forward analysis
- ‚úÖ Understand worst-case scenarios (Monte Carlo)
- ‚úÖ Verify live execution matches backtests
- ‚úÖ Build proper risk controls
- ‚úÖ Deploy with confidence

**Start with Month 1-2 infrastructure setup, then iterate based on results.**

**Remember:** It's better to spend 6 months testing and go live successfully than to rush and lose capital in 6 weeks.

---

**Next Steps:**
1. Review this document with your team
2. Download historical data (Week 1 task)
3. Set up Nautilus environment
4. Begin Month 1 implementation
5. Schedule weekly progress reviews

**Good luck! Build it right, test thoroughly, and deploy successfully! üöÄüìà**
